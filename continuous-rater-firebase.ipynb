{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add user input\n",
    "Fill in the variables in the cell below with the following information\n",
    "\n",
    "- `experiment` = name of experiment (outermost collection) in Firebase\n",
    "- `local_folder` = name of folder you want created locally and populated with data\n",
    "- `credential_path` = path to .json Firebase SDK service account key (explained [here](https://firebase.google.com/docs/admin/setup))\n",
    "- `firebase_project_name` = name of project in Firebase (click Project Overview in the Firebase console to see name)\n",
    "- `groups` = array of group names (as set by userGroup in src/utils.js and found as collections in the 'subject' document in your Firebase), each enclosed in single quotes and separated by commas\n",
    "- `rating_types` = array of rating types, each enclosed in single quotes and separated by commas (same as ratingTypes from src/utils.js)\n",
    "- `movie_names` = array of movie names, as written in Firebase stimuli table (no spaces), each enclosed in single quotes and separated by commas\n",
    "- `vid_lens` = dictionary of video durations, where each entry contains the movie name as key and the movie duration (in seconds) as value (e.g. {'movie1': 100, 'movie2': 150, 'movie3': 120}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER VARIABLES (FILL IN HERE)\n",
    "experiment = 'wasabi-online'\n",
    "local_folder = '/Users/jasondavis/Documents/MATLAB/wasabi-online'\n",
    "credential_path = '/Users/jasondavis/Documents/Downloads/continuous-rater-jad-firebase-adminsdk-2ie9g-0080d92b8a.json'\n",
    "firebase_project_name = 'continuous-rater-jad'\n",
    "groups = ['mTurk Group'] # possible to only have on group, or can use multiple for organizational purposes\n",
    "\n",
    "rating_types = ['pleasant', 'unpleasant', 'calm', 'aroused', 'funny', 'happy', 'angry', 'sad', 'disgusted', 'afraid', 'suprised']\n",
    "movie_names = ['KungFuryPart1', 'KungFuryPart2']\n",
    "vid_lens = {'KungFuryPart1': 931, 'KungFuryPart2': 931} # example values, fill in with your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up communication with Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate(credential_path)\n",
    "firebase_admin.initialize_app(cred, {\n",
    "  'projectId': firebase_project_name,\n",
    "})\n",
    "\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data structures and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data structures\n",
    "subject_rating_dict = {}\n",
    "movie_q_count_dict = {}\n",
    "sub_to_mov = {}\n",
    "mov_to_sub = {}\n",
    "\n",
    "# initialize directory structure\n",
    "directories = []\n",
    "directories.append(f'{local_folder}/')\n",
    "directories.append(f'{local_folder}/Long/')\n",
    "directories.append(f'{local_folder}/Blanks/')\n",
    "directories.append(f'{local_folder}/Subjects/')\n",
    "directories.append(f'{local_folder}/Subjects/Incomplete/')\n",
    "directories.append(f'{local_folder}/Subjects/Groups/')\n",
    "directories.append(f'{local_folder}/Summary/')\n",
    "directories.append(f'{local_folder}/Ratings/')\n",
    "for movie in movie_names:\n",
    "    for rating in rating_types:\n",
    "        combo = movie + \"-\" + rating\n",
    "        movie_q_count_dict[combo] = 0\n",
    "        mov_to_sub[combo] = []\n",
    "        directories.append(f'{local_folder}/Ratings/{combo}/')\n",
    "        \n",
    "for directory in directories:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create blank pandas dataframes of proper shape to fill in with rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use provided movie durations to create blank dataframe of proper length for each movie\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "for movie in movie_names:\n",
    "    curr_vid_len = vid_lens[movie] + 3 # add buffer time\n",
    "    init_ratings = np.full(curr_vid_len, -1)\n",
    "    curr_df = pd.DataFrame({'rating': init_ratings})\n",
    "    curr_df.to_csv(os.path.join(blanks_path, f'{movie}.csv')) # write out to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read blank dataframes back in and store in dictionary\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "blank_pd_dict = {}\n",
    "directory_list = glob.glob(os.path.join(blanks_path, '*.csv'))\n",
    "for file in directory_list:\n",
    "    curr_df = pd.read_csv(file)\n",
    "    drop_df = curr_df.drop(labels='Unnamed: 0', axis=1)\n",
    "    movie = os.path.basename(file).split('.')[0]\n",
    "    blank_pd_dict[movie] = drop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which subjects completed task, and save subject info to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730915693.768898  483025 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1730915693.793506  483025 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "# create good and bad subject lists (based on completion)\n",
    "good_id_master_list = []\n",
    "bad_id_master_list = []\n",
    "\n",
    "for group in groups:\n",
    "    good_id_list = [] # stores participants who completed HIT\n",
    "    bad_id_list = [] # stores participants who started but didn't complete HIT\n",
    "    sub_list = []\n",
    "\n",
    "    group_path = f'{experiment}/subjects/{group}'\n",
    "    group_collection = db.collection(group_path)\n",
    "    group_subs = group_collection.stream()\n",
    "\n",
    "    for sub in group_subs:\n",
    "        sub_dict = sub.to_dict()\n",
    "        if 'currentState' in sub_dict: # check to see if subject even started HIT\n",
    "            if sub_dict['currentState'] == 'debrief' or 'HIT_complete' in sub_dict: # only keep subs who finished\n",
    "                good_id_list.append(sub.id)\n",
    "                good_id_master_list.append(sub.id)\n",
    "                curr = pd.Series(sub_dict)\n",
    "                sub_list.append(curr)\n",
    "                file_path = f'{local_folder}/Subjects/{sub.id}.csv'\n",
    "                curr.to_csv(file_path)\n",
    "        else:\n",
    "            bad_id_list.append(sub.id)\n",
    "            bad_id_master_list.append(sub.id)\n",
    "            curr = pd.Series(sub_dict)\n",
    "            file_path = f'{local_folder}/Subjects/Incomplete/{sub.id}.csv'\n",
    "            curr.to_csv(file_path)\n",
    "\n",
    "    group_df = pd.DataFrame(sub_list)\n",
    "    group_df.to_csv(f'{local_folder}/Subjects/Groups/{group}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all ratings from subjects who completed task and store locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over subjects and gets ratings from database to store in local dictionary\n",
    "# also counts number of subjects that have rated each question\n",
    "# links subjects to movies and movies to subjects\n",
    "good_id_set = set(good_id_master_list) # removes repeats\n",
    "\n",
    "for good_id in good_id_set: \n",
    "    sub_to_mov[good_id] = []\n",
    "    movie_list = []\n",
    "    collection_path = f'{experiment}/ratings/{good_id}'\n",
    "    curr_sub_ratings = db.collection(collection_path)\n",
    "    HITs = curr_sub_ratings.stream()\n",
    "\n",
    "    curr_movie_dict = {}\n",
    "    for HIT in HITs:\n",
    "        sub_to_mov[good_id].append(HIT.id)\n",
    "        mov_to_sub[HIT.id].append(good_id)\n",
    "        curr_movie_dict[HIT.id] = HIT.to_dict()\n",
    "        movie_q_count_dict[HIT.id] += 1\n",
    "\n",
    "    if good_id in subject_rating_dict:\n",
    "        updated = subject_rating_dict[good_id].append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = updated\n",
    "    else:\n",
    "        movie_list.append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = movie_list\n",
    "\n",
    "movie_counts = pd.Series(movie_q_count_dict)\n",
    "movie_counts.to_csv(f'{local_folder}/Summary/Movie_Counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out rating dictionary to .csv rating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes file containing rating-timestamp pairs for each subject to folder for each movie-rating pairing\n",
    "for good_id in good_id_set:\n",
    "    curr_sub = subject_rating_dict[good_id]\n",
    "    for dictionary in curr_sub:\n",
    "        for movie_rating in dictionary:\n",
    "            words = movie_rating.split('-')\n",
    "            blank_mov_pd = blank_pd_dict[words[0]].copy()\n",
    "            rating_dict = dictionary[movie_rating]\n",
    "            for timestamp in rating_dict:\n",
    "                blank_mov_pd.iloc[int(timestamp)] = rating_dict[timestamp]  \n",
    "            file_path = f'{local_folder}/Ratings/{movie_rating}/{good_id}.csv'\n",
    "            blank_mov_pd.to_csv(file_path)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine subject and rating info together to create long format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the base frame for appending\n",
    "cols = ['workerId', 'movie', 'ratingType', 'HIT_complete', 'age', 'assignmentId', 'birth', 'consentStatus', 'currentState', \\\n",
    "'ethnicity', 'feedback', 'handed', 'hitId', 'nativeLang', 'race', 'sex', 'startTime', \\\n",
    "'userId', 'mostRecentTime', 'timeStamp', 'ratingScore']\n",
    "\n",
    "base_frame = pd.DataFrame(np.nan, index=[0], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this take individual local csvs and turns them into long format per movie per rating per subject\n",
    "dir_list = glob.glob(f'{local_folder}/Ratings/*')\n",
    "master_long = base_frame.copy()\n",
    "\n",
    "for directory in dir_list:\n",
    "    path = directory + '/*.csv'\n",
    "    rating_list = glob.glob(path)\n",
    "    for file in rating_list:\n",
    "        sub_id = os.path.basename(file).split('.')[0]\n",
    "        movie_rating = file.split('/')[2]\n",
    "        movie = movie_rating.split('-')[0]\n",
    "        rating = movie_rating.split('-')[0]       \n",
    "\n",
    "        # this should check and not rewrite files that already exist (speeds up process)\n",
    "        if not os.path.isfile(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv'):\n",
    "            subject_long = base_frame.copy()\n",
    "            rating_pd = pd.read_csv(file)\n",
    "            sub_path = f'{local_folder}/Subjects/{sub_id}.csv'\n",
    "            if os.path.isfile(sub_path):\n",
    "                sub_pd = pd.read_csv(sub_path)\n",
    "                title_list = sub_pd['Unnamed: 0'].values\n",
    "                rename_dict = {}\n",
    "                counter = 0\n",
    "                for title in title_list:\n",
    "                    rename_dict[counter] = title\n",
    "                    counter += 1   \n",
    "                new_sub_pd = sub_pd.transpose().rename(columns=rename_dict).drop(['Unnamed: 0'])\n",
    "\n",
    "                new_pd = base_frame.copy()\n",
    "                new_pd['movie'] = movie\n",
    "                new_pd['ratingType'] = rating\n",
    "\n",
    "                for category in base_frame:\n",
    "                    if category in new_sub_pd:\n",
    "                        new_pd[category] = new_sub_pd[category].values\n",
    "\n",
    "                timestamp_dict = rating_pd.transpose().drop(['Unnamed: 0'])\n",
    "                copy_pd = new_pd.copy()\n",
    "                prevScore = -1\n",
    "                rating_counter = 0\n",
    "                for timestamp in timestamp_dict:\n",
    "                    ratingScore = timestamp_dict[timestamp].values\n",
    "                    if ratingScore != -1:\n",
    "                        prevScore = ratingScore\n",
    "                    else:\n",
    "                        ratingScore = prevScore\n",
    "\n",
    "                    copy_pd['timeStamp'] = timestamp\n",
    "                    copy_pd['ratingScore'] = ratingScore\n",
    "                    subject_long = pd.concat([subject_long, copy_pd], ignore_index=True)\n",
    "\n",
    "                subject_long = subject_long.drop([0])\n",
    "                subject_long.to_csv(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this appends all individual long format files into one giant long format panda\n",
    "master_long = base_frame.copy()\n",
    "long_list = glob.glob(f'{local_folder}/Long/*.csv')\n",
    "\n",
    "for file in long_list:\n",
    "    curr_pd = pd.read_csv(file)\n",
    "    master_long = pd.concat([master_long, curr_pd])\n",
    "\n",
    "master_long.drop([0])\n",
    "master_long.to_csv(f'{local_folder}/master_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in saved copy\n",
    "master_long = pd.read_csv(f'{local_folder}/master_long.csv')\n",
    "master_long.drop(labels=[0], inplace=True)\n",
    "master_long.drop(labels=['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "sub_list = master_long['workerId'].unique()\n",
    "movie_list = master_long['movie'].unique()\n",
    "rating_list = master_long['ratingType'].unique()\n",
    "movie = movie_list[0]\n",
    "rating = rating_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerId</th>\n",
       "      <th>movie</th>\n",
       "      <th>ratingType</th>\n",
       "      <th>HIT_complete</th>\n",
       "      <th>age</th>\n",
       "      <th>assignmentId</th>\n",
       "      <th>birth</th>\n",
       "      <th>consentStatus</th>\n",
       "      <th>currentState</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>handed</th>\n",
       "      <th>hitId</th>\n",
       "      <th>nativeLang</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>startTime</th>\n",
       "      <th>userId</th>\n",
       "      <th>mostRecentTime</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>ratingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>936000037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greece</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greek</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>HBDOOqo5RWe5pUSBW9h7e69EboI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>936000037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greece</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greek</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>HBDOOqo5RWe5pUSBW9h7e69EboI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>936000037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greece</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greek</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>HBDOOqo5RWe5pUSBW9h7e69EboI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>936000037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greece</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greek</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>HBDOOqo5RWe5pUSBW9h7e69EboI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>936000037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greece</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>936000037.0</td>\n",
       "      <td>greek</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-28 17:08:08.215000+00:00</td>\n",
       "      <td>HBDOOqo5RWe5pUSBW9h7e69EboI3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18676</th>\n",
       "      <td>477182049.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italian</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>JmTcZqgMJse6BwwYmY8P03yOh853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18677</th>\n",
       "      <td>477182049.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italian</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>JmTcZqgMJse6BwwYmY8P03yOh853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>930.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18678</th>\n",
       "      <td>477182049.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italian</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>JmTcZqgMJse6BwwYmY8P03yOh853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>931.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18679</th>\n",
       "      <td>477182049.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italian</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>JmTcZqgMJse6BwwYmY8P03yOh853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>932.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18680</th>\n",
       "      <td>477182049.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>477182049.0</td>\n",
       "      <td>Italian</td>\n",
       "      <td>['White / Caucasian']</td>\n",
       "      <td>male</td>\n",
       "      <td>2024-10-26 16:37:31.553000+00:00</td>\n",
       "      <td>JmTcZqgMJse6BwwYmY8P03yOh853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>933.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18680 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          workerId       movie  ratingType                      HIT_complete  \\\n",
       "1      936000037.0  jasondavis  jasondavis  2024-10-28 17:08:08.215000+00:00   \n",
       "2      936000037.0  jasondavis  jasondavis  2024-10-28 17:08:08.215000+00:00   \n",
       "3      936000037.0  jasondavis  jasondavis  2024-10-28 17:08:08.215000+00:00   \n",
       "4      936000037.0  jasondavis  jasondavis  2024-10-28 17:08:08.215000+00:00   \n",
       "5      936000037.0  jasondavis  jasondavis  2024-10-28 17:08:08.215000+00:00   \n",
       "...            ...         ...         ...                               ...   \n",
       "18676  477182049.0  jasondavis  jasondavis  2024-10-26 16:37:31.553000+00:00   \n",
       "18677  477182049.0  jasondavis  jasondavis  2024-10-26 16:37:31.553000+00:00   \n",
       "18678  477182049.0  jasondavis  jasondavis  2024-10-26 16:37:31.553000+00:00   \n",
       "18679  477182049.0  jasondavis  jasondavis  2024-10-26 16:37:31.553000+00:00   \n",
       "18680  477182049.0  jasondavis  jasondavis  2024-10-26 16:37:31.553000+00:00   \n",
       "\n",
       "        age  assignmentId   birth consentStatus currentState     ethnicity  \\\n",
       "1      33.0   936000037.0  greece        signed     complete  not_hispanic   \n",
       "2      33.0   936000037.0  greece        signed     complete  not_hispanic   \n",
       "3      33.0   936000037.0  greece        signed     complete  not_hispanic   \n",
       "4      33.0   936000037.0  greece        signed     complete  not_hispanic   \n",
       "5      33.0   936000037.0  greece        signed     complete  not_hispanic   \n",
       "...     ...           ...     ...           ...          ...           ...   \n",
       "18676  42.0   477182049.0   Italy        signed     complete  not_hispanic   \n",
       "18677  42.0   477182049.0   Italy        signed     complete  not_hispanic   \n",
       "18678  42.0   477182049.0   Italy        signed     complete  not_hispanic   \n",
       "18679  42.0   477182049.0   Italy        signed     complete  not_hispanic   \n",
       "18680  42.0   477182049.0   Italy        signed     complete  not_hispanic   \n",
       "\n",
       "       ... handed        hitId  nativeLang                   race   sex  \\\n",
       "1      ...  right  936000037.0       greek  ['White / Caucasian']  male   \n",
       "2      ...  right  936000037.0       greek  ['White / Caucasian']  male   \n",
       "3      ...  right  936000037.0       greek  ['White / Caucasian']  male   \n",
       "4      ...  right  936000037.0       greek  ['White / Caucasian']  male   \n",
       "5      ...  right  936000037.0       greek  ['White / Caucasian']  male   \n",
       "...    ...    ...          ...         ...                    ...   ...   \n",
       "18676  ...  right  477182049.0     Italian  ['White / Caucasian']  male   \n",
       "18677  ...  right  477182049.0     Italian  ['White / Caucasian']  male   \n",
       "18678  ...  right  477182049.0     Italian  ['White / Caucasian']  male   \n",
       "18679  ...  right  477182049.0     Italian  ['White / Caucasian']  male   \n",
       "18680  ...  right  477182049.0     Italian  ['White / Caucasian']  male   \n",
       "\n",
       "                              startTime                        userId  \\\n",
       "1      2024-10-28 17:08:08.215000+00:00  HBDOOqo5RWe5pUSBW9h7e69EboI3   \n",
       "2      2024-10-28 17:08:08.215000+00:00  HBDOOqo5RWe5pUSBW9h7e69EboI3   \n",
       "3      2024-10-28 17:08:08.215000+00:00  HBDOOqo5RWe5pUSBW9h7e69EboI3   \n",
       "4      2024-10-28 17:08:08.215000+00:00  HBDOOqo5RWe5pUSBW9h7e69EboI3   \n",
       "5      2024-10-28 17:08:08.215000+00:00  HBDOOqo5RWe5pUSBW9h7e69EboI3   \n",
       "...                                 ...                           ...   \n",
       "18676  2024-10-26 16:37:31.553000+00:00  JmTcZqgMJse6BwwYmY8P03yOh853   \n",
       "18677  2024-10-26 16:37:31.553000+00:00  JmTcZqgMJse6BwwYmY8P03yOh853   \n",
       "18678  2024-10-26 16:37:31.553000+00:00  JmTcZqgMJse6BwwYmY8P03yOh853   \n",
       "18679  2024-10-26 16:37:31.553000+00:00  JmTcZqgMJse6BwwYmY8P03yOh853   \n",
       "18680  2024-10-26 16:37:31.553000+00:00  JmTcZqgMJse6BwwYmY8P03yOh853   \n",
       "\n",
       "      mostRecentTime  timeStamp  ratingScore  \n",
       "1                NaN        0.0         50.0  \n",
       "2                NaN        1.0         50.0  \n",
       "3                NaN        2.0         50.0  \n",
       "4                NaN        3.0         50.0  \n",
       "5                NaN        4.0         50.0  \n",
       "...              ...        ...          ...  \n",
       "18676            NaN      929.0         74.0  \n",
       "18677            NaN      930.0         74.0  \n",
       "18678            NaN      931.0         74.0  \n",
       "18679            NaN      932.0         74.0  \n",
       "18680            NaN      933.0         74.0  \n",
       "\n",
       "[18680 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
