{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasondavis/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add user input\n",
    "Fill in the variables in the cell below with the following information\n",
    "\n",
    "- `experiment` = name of experiment (outermost collection) in Firebase\n",
    "- `local_folder` = name of folder you want created locally and populated with data\n",
    "- `credential_path` = path to .json Firebase SDK service account key (explained [here](https://firebase.google.com/docs/admin/setup))\n",
    "- `firebase_project_name` = name of project in Firebase (click Project Overview in the Firebase console to see name)\n",
    "- `groups` = array of group names (as set by userGroup in src/utils.js and found as collections in the 'subject' document in your Firebase), each enclosed in single quotes and separated by commas\n",
    "- `rating_types` = array of rating types, each enclosed in single quotes and separated by commas (same as ratingTypes from src/utils.js)\n",
    "- `movie_names` = array of movie names, as written in Firebase stimuli table (no spaces), each enclosed in single quotes and separated by commas\n",
    "- `vid_lens` = dictionary of video durations, where each entry contains the movie name as key and the movie duration (in seconds) as value (e.g. {'movie1': 100, 'movie2': 150, 'movie3': 120}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER VARIABLES (FILL IN HERE)\n",
    "experiment = 'wasabi-online'\n",
    "local_folder = '/Users/jasondavis/Documents/MATLAB/state_affect_mapping_jad/wasabi_online/'\n",
    "credential_path = '/Users/jasondavis/Documents/Downloads/continuous-rater-jad-firebase-adminsdk-2ie9g-0080d92b8a.json'\n",
    "firebase_project_name = 'continuous-rater-jad'\n",
    "groups = ['Kung Fury Study 3'] # possible to only have on group, or can use multiple for organizational purposes\n",
    "rating_types = ['pleasant', 'unpleasant', 'calm', 'aroused', 'funny', 'happy', 'angry', 'sad', 'disgusted', 'afraid', 'surprised', 'neutral']\n",
    "movie_names = ['ColdWar', 'KungFuryPart1', 'KungFuryPart2']\n",
    "vid_lens = {'ColdWar':999,'KungFuryPart1': 931, 'KungFuryPart2': 931} # example values, fill in with your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up communication with Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate(credential_path)\n",
    "firebase_admin.initialize_app(cred, {\n",
    "  'projectId': firebase_project_name,\n",
    "})\n",
    "\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data structures and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data structures\n",
    "subject_rating_dict = {}\n",
    "movie_q_count_dict = {}\n",
    "sub_to_mov = {}\n",
    "mov_to_sub = {}\n",
    "\n",
    "# initialize directory structure\n",
    "directories = []\n",
    "directories.append(f'{local_folder}/')\n",
    "directories.append(f'{local_folder}/Long/')\n",
    "directories.append(f'{local_folder}/Blanks/')\n",
    "directories.append(f'{local_folder}/Subjects/')\n",
    "directories.append(f'{local_folder}/Subjects/Incomplete/')\n",
    "directories.append(f'{local_folder}/Subjects/Groups/')\n",
    "directories.append(f'{local_folder}/Summary/')\n",
    "directories.append(f'{local_folder}/Ratings/')\n",
    "for movie in movie_names:\n",
    "    for rating in rating_types:\n",
    "        combo = movie + \"-\" + rating\n",
    "        movie_q_count_dict[combo] = 0\n",
    "        mov_to_sub[combo] = []\n",
    "        directories.append(f'{local_folder}/Ratings/{combo}/')\n",
    "        \n",
    "for directory in directories:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create blank pandas dataframes of proper shape to fill in with rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use provided movie durations to create blank dataframe of proper length for each movie\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "for movie in movie_names:\n",
    "    curr_vid_len = vid_lens[movie] + 3 # add buffer time\n",
    "    init_ratings = np.full(curr_vid_len, -1)\n",
    "    curr_df = pd.DataFrame({'rating': init_ratings})\n",
    "    curr_df.to_csv(os.path.join(blanks_path, f'{movie}.csv')) # write out to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read blank dataframes back in and store in dictionary\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "blank_pd_dict = {}\n",
    "directory_list = glob.glob(os.path.join(blanks_path, '*.csv'))\n",
    "for file in directory_list:\n",
    "    curr_df = pd.read_csv(file)\n",
    "    drop_df = curr_df.drop(labels='Unnamed: 0', axis=1)\n",
    "    movie = os.path.basename(file).split('.')[0]\n",
    "    blank_pd_dict[movie] = drop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which subjects completed task, and save subject info to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create good and bad subject lists (based on completion)\n",
    "good_id_master_list = []\n",
    "bad_id_master_list = []\n",
    "\n",
    "for group in groups:\n",
    "    good_id_list = [] # stores participants who completed HIT\n",
    "    bad_id_list = [] # stores participants who started but didn't complete HIT\n",
    "    sub_list = []\n",
    "\n",
    "    group_path = f'{experiment}/subjects/{group}'\n",
    "    group_collection = db.collection(group_path)\n",
    "    group_subs = group_collection.stream()\n",
    "\n",
    "    for sub in group_subs:\n",
    "        sub_dict = sub.to_dict()\n",
    "        if 'currentState' in sub_dict: # check to see if subject even started HIT\n",
    "            if sub_dict['currentState'] == 'debrief' or 'HIT_complete' in sub_dict: # only keep subs who finished\n",
    "                good_id_list.append(sub.id)\n",
    "                good_id_master_list.append(sub.id)\n",
    "                curr = pd.Series(sub_dict)\n",
    "                sub_list.append(curr)\n",
    "                file_path = f'{local_folder}/Subjects/{sub.id}.csv'\n",
    "                curr.to_csv(file_path)\n",
    "        else:\n",
    "            bad_id_list.append(sub.id)\n",
    "            bad_id_master_list.append(sub.id)\n",
    "            curr = pd.Series(sub_dict)\n",
    "            file_path = f'{local_folder}/Subjects/Incomplete/{sub.id}.csv'\n",
    "            curr.to_csv(file_path)\n",
    "\n",
    "    group_df = pd.DataFrame(sub_list)\n",
    "    group_df.to_csv(f'{local_folder}/Subjects/Groups/{group}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all ratings from subjects who completed task and store locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over subjects and gets ratings from database to store in local dictionary\n",
    "# also counts number of subjects that have rated each question\n",
    "# links subjects to movies and movies to subjects\n",
    "good_id_set = set(good_id_master_list) # removes repeats\n",
    "\n",
    "for good_id in good_id_set: \n",
    "    sub_to_mov[good_id] = []\n",
    "    movie_list = []\n",
    "    collection_path = f'{experiment}/ratings/{good_id}'\n",
    "    curr_sub_ratings = db.collection(collection_path)\n",
    "    HITs = curr_sub_ratings.stream()\n",
    "\n",
    "    curr_movie_dict = {}\n",
    "    for HIT in HITs:\n",
    "        sub_to_mov[good_id].append(HIT.id)\n",
    "        mov_to_sub[HIT.id].append(good_id)\n",
    "        curr_movie_dict[HIT.id] = HIT.to_dict()\n",
    "        movie_q_count_dict[HIT.id] += 1\n",
    "\n",
    "    if good_id in subject_rating_dict:\n",
    "        updated = subject_rating_dict[good_id].append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = updated\n",
    "    else:\n",
    "        movie_list.append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = movie_list\n",
    "\n",
    "movie_counts = pd.Series(movie_q_count_dict)\n",
    "movie_counts.to_csv(f'{local_folder}/Summary/Movie_Counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out rating dictionary to .csv rating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for good_id in good_id_set:\n",
    "    curr_sub = subject_rating_dict[good_id]\n",
    "    for dictionary in curr_sub:\n",
    "        for movie_rating in dictionary:\n",
    "            words = movie_rating.split('-')\n",
    "            blank_mov_pd = blank_pd_dict[words[0]].copy()\n",
    "            rating_dict = dictionary[movie_rating]\n",
    "\n",
    "            # Assume blank_mov_pd initially only has a column for ratings.\n",
    "            # Let's add a column for comprehension answers:\n",
    "            if 'comprehension' not in blank_mov_pd.columns:\n",
    "                blank_mov_pd['comprehension'] = ''\n",
    "\n",
    "            for timestamp, value in rating_dict.items():\n",
    "                # Check if timestamp is digit and within range of DataFrame index\n",
    "                if timestamp.isdigit():\n",
    "                    idx = int(timestamp)\n",
    "                    if idx < len(blank_mov_pd):\n",
    "                        # store rating (assuming ratings are digits or numbers)\n",
    "                        blank_mov_pd.at[idx, 'rating'] = value  # store rating in 'rating' column\n",
    "                else:\n",
    "                    # For comprehension keys (non-digit), store comprehension answers (letters)\n",
    "                    # This depends on how you want to store comprehension values:\n",
    "                    # Here I assume the key itself is a comprehension question, and its value is the answer\n",
    "                    # We'll append or set them in a separate dict or DataFrame column\n",
    "                    \n",
    "                    # Example: store comprehension answers in a dictionary on the DataFrame or a separate structure\n",
    "                    # If comprehension answers correspond to special rows or positions, define accordingly\n",
    "                    # For example, store comprehension answers in the 'comprehension' column at a fixed row (e.g., 0)\n",
    "                    \n",
    "                    blank_mov_pd.at[0, 'comprehension'] += str(value) + ';'  # Append answers as a string separated by semicolon\n",
    "\n",
    "            # Save file\n",
    "            file_path = f'{local_folder}/Ratings/{movie_rating}/{good_id}.csv'\n",
    "            blank_mov_pd.to_csv(file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine subject and rating info together to create long format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the base frame for appending\n",
    "cols = ['workerId', 'movie', 'ratingType', 'HIT_complete', 'age', 'assignmentId', 'birth', 'consentStatus', 'currentState', \\\n",
    "'ethnicity', 'feedback', 'handed', 'hitId', 'nativeLang', 'race', 'sex', 'startTime', \\\n",
    "'userId', 'mostRecentTime', 'timeStamp', 'ratingScore']\n",
    "\n",
    "base_frame = pd.DataFrame(np.nan, index=[0], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this take individual local csvs and turns them into long format per movie per rating per subject\n",
    "dir_list = glob.glob(f'{local_folder}/Ratings/*')\n",
    "master_long = base_frame.copy()\n",
    "\n",
    "for directory in dir_list:\n",
    "    path = directory + '/*.csv'\n",
    "    rating_list = glob.glob(path)\n",
    "    for file in rating_list:\n",
    "        sub_id = os.path.basename(file).split('.')[0]\n",
    "        movie_rating = file.split('/')[2]\n",
    "        movie = movie_rating.split('-')[0]\n",
    "        rating = movie_rating.split('-')[0]       \n",
    "\n",
    "        # this should check and not rewrite files that already exist (speeds up process)\n",
    "        if not os.path.isfile(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv'):\n",
    "            subject_long = base_frame.copy()\n",
    "            rating_pd = pd.read_csv(file)\n",
    "            sub_path = f'{local_folder}/Subjects/{sub_id}.csv'\n",
    "            if os.path.isfile(sub_path):\n",
    "                sub_pd = pd.read_csv(sub_path)\n",
    "                title_list = sub_pd['Unnamed: 0'].values\n",
    "                rename_dict = {}\n",
    "                counter = 0\n",
    "                for title in title_list:\n",
    "                    rename_dict[counter] = title\n",
    "                    counter += 1   \n",
    "                new_sub_pd = sub_pd.transpose().rename(columns=rename_dict).drop(['Unnamed: 0'])\n",
    "\n",
    "                new_pd = base_frame.copy()\n",
    "                new_pd['movie'] = movie\n",
    "                new_pd['ratingType'] = rating\n",
    "\n",
    "                for category in base_frame:\n",
    "                    if category in new_sub_pd:\n",
    "                        new_pd[category] = new_sub_pd[category].values\n",
    "\n",
    "                timestamp_dict = rating_pd.transpose().drop(['Unnamed: 0'])\n",
    "                copy_pd = new_pd.copy()\n",
    "                prevScore = -1\n",
    "                rating_counter = 0\n",
    "                for timestamp in timestamp_dict:\n",
    "                    ratingScore = timestamp_dict[timestamp].values\n",
    "                    if ratingScore != -1:\n",
    "                        prevScore = ratingScore\n",
    "                    else:\n",
    "                        ratingScore = prevScore\n",
    "\n",
    "                    copy_pd['timeStamp'] = timestamp\n",
    "                    copy_pd['ratingScore'] = ratingScore\n",
    "                    subject_long = pd.concat([subject_long, copy_pd], ignore_index=True)\n",
    "\n",
    "                subject_long = subject_long.drop([0])\n",
    "                subject_long.to_csv(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this appends all individual long format files into one giant long format panda\n",
    "master_long = base_frame.copy()\n",
    "long_list = glob.glob(f'{local_folder}/Long/*.csv')\n",
    "\n",
    "for file in long_list:\n",
    "    curr_pd = pd.read_csv(file)\n",
    "    master_long = pd.concat([master_long, curr_pd])\n",
    "\n",
    "master_long.drop([0])\n",
    "master_long.to_csv(f'{local_folder}/master_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in saved copy\n",
    "master_long = pd.read_csv(f'{local_folder}/master_long.csv')\n",
    "master_long.drop(labels=[0], inplace=True)\n",
    "master_long.drop(labels=['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "sub_list = master_long['workerId'].unique()\n",
    "movie_list = master_long['movie'].unique()\n",
    "rating_list = master_long['ratingType'].unique()\n",
    "movie = movie_list[0]\n",
    "rating = rating_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerId</th>\n",
       "      <th>movie</th>\n",
       "      <th>ratingType</th>\n",
       "      <th>HIT_complete</th>\n",
       "      <th>age</th>\n",
       "      <th>assignmentId</th>\n",
       "      <th>birth</th>\n",
       "      <th>consentStatus</th>\n",
       "      <th>currentState</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>handed</th>\n",
       "      <th>hitId</th>\n",
       "      <th>nativeLang</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>startTime</th>\n",
       "      <th>userId</th>\n",
       "      <th>mostRecentTime</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>ratingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240886</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240887</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>930.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240888</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>931.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240889</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>932.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240890</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>933.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240890 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           workerId       movie  ratingType                      HIT_complete  \\\n",
       "1       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "2       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "3       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "4       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "5       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "...             ...         ...         ...                               ...   \n",
       "240886  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240887  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240888  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240889  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240890  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "\n",
       "         age  assignmentId          birth consentStatus currentState  \\\n",
       "1       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "2       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "3       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "4       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "5       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "...      ...           ...            ...           ...          ...   \n",
       "240886  31.0   405819037.0  South Africa         signed     complete   \n",
       "240887  31.0   405819037.0  South Africa         signed     complete   \n",
       "240888  31.0   405819037.0  South Africa         signed     complete   \n",
       "240889  31.0   405819037.0  South Africa         signed     complete   \n",
       "240890  31.0   405819037.0  South Africa         signed     complete   \n",
       "\n",
       "           ethnicity  ... handed        hitId  nativeLang  \\\n",
       "1       not_hispanic  ...  right  521709877.0     English   \n",
       "2       not_hispanic  ...  right  521709877.0     English   \n",
       "3       not_hispanic  ...  right  521709877.0     English   \n",
       "4       not_hispanic  ...  right  521709877.0     English   \n",
       "5       not_hispanic  ...  right  521709877.0     English   \n",
       "...              ...  ...    ...          ...         ...   \n",
       "240886      hispanic  ...  right  405819037.0    English    \n",
       "240887      hispanic  ...  right  405819037.0    English    \n",
       "240888      hispanic  ...  right  405819037.0    English    \n",
       "240889      hispanic  ...  right  405819037.0    English    \n",
       "240890      hispanic  ...  right  405819037.0    English    \n",
       "\n",
       "                                race     sex  \\\n",
       "1       ['Black / African-American']  female   \n",
       "2       ['Black / African-American']  female   \n",
       "3       ['Black / African-American']  female   \n",
       "4       ['Black / African-American']  female   \n",
       "5       ['Black / African-American']  female   \n",
       "...                              ...     ...   \n",
       "240886  ['Black / African-American']    male   \n",
       "240887  ['Black / African-American']    male   \n",
       "240888  ['Black / African-American']    male   \n",
       "240889  ['Black / African-American']    male   \n",
       "240890  ['Black / African-American']    male   \n",
       "\n",
       "                               startTime                        userId  \\\n",
       "1       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "2       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "3       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "4       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "5       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "...                                  ...                           ...   \n",
       "240886  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240887  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240888  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240889  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240890  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "\n",
       "       mostRecentTime  timeStamp  ratingScore  \n",
       "1                 NaN        0.0         50.0  \n",
       "2                 NaN        1.0         50.0  \n",
       "3                 NaN        2.0         50.0  \n",
       "4                 NaN        3.0         50.0  \n",
       "5                 NaN        4.0         50.0  \n",
       "...               ...        ...          ...  \n",
       "240886            NaN      929.0         50.0  \n",
       "240887            NaN      930.0         50.0  \n",
       "240888            NaN      931.0         50.0  \n",
       "240889            NaN      932.0         50.0  \n",
       "240890            NaN      933.0         50.0  \n",
       "\n",
       "[240890 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
