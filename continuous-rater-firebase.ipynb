{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add user input\n",
    "Fill in the variables in the cell below with the following information\n",
    "\n",
    "- `experiment` = name of experiment (outermost collection) in Firebase\n",
    "- `local_folder` = name of folder you want created locally and populated with data\n",
    "- `credential_path` = path to .json Firebase SDK service account key (explained [here](https://firebase.google.com/docs/admin/setup))\n",
    "- `firebase_project_name` = name of project in Firebase (click Project Overview in the Firebase console to see name)\n",
    "- `groups` = array of group names (as set by userGroup in src/utils.js and found as collections in the 'subject' document in your Firebase), each enclosed in single quotes and separated by commas\n",
    "- `rating_types` = array of rating types, each enclosed in single quotes and separated by commas (same as ratingTypes from src/utils.js)\n",
    "- `movie_names` = array of movie names, as written in Firebase stimuli table (no spaces), each enclosed in single quotes and separated by commas\n",
    "- `vid_lens` = dictionary of video durations, where each entry contains the movie name as key and the movie duration (in seconds) as value (e.g. {'movie1': 100, 'movie2': 150, 'movie3': 120}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER VARIABLES (FILL IN HERE)\n",
    "experiment = 'wasabi-online'\n",
    "local_folder = '/Users/jasondavis/Documents/MATLAB/state_affect_mapping_jad/wasabi_online/'\n",
    "credential_path = '/Users/jasondavis/Documents/Downloads/continuous-rater-jad-firebase-adminsdk-2ie9g-0080d92b8a.json'\n",
    "firebase_project_name = 'continuous-rater-jad'\n",
    "groups = ['Prolific Group'] # possible to only have on group, or can use multiple for organizational purposes\n",
    "rating_types = ['pleasant', 'unpleasant', 'calm', 'aroused', 'funny', 'happy', 'angry', 'sad', 'disgusted', 'afraid', 'suprised']\n",
    "movie_names = ['KungFuryPart1', 'KungFuryPart2']\n",
    "vid_lens = {'KungFuryPart1': 931, 'KungFuryPart2': 931} # example values, fill in with your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up communication with Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate(credential_path)\n",
    "firebase_admin.initialize_app(cred, {\n",
    "  'projectId': firebase_project_name,\n",
    "})\n",
    "\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data structures and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data structures\n",
    "subject_rating_dict = {}\n",
    "movie_q_count_dict = {}\n",
    "sub_to_mov = {}\n",
    "mov_to_sub = {}\n",
    "\n",
    "# initialize directory structure\n",
    "directories = []\n",
    "directories.append(f'{local_folder}/')\n",
    "directories.append(f'{local_folder}/Long/')\n",
    "directories.append(f'{local_folder}/Blanks/')\n",
    "directories.append(f'{local_folder}/Subjects/')\n",
    "directories.append(f'{local_folder}/Subjects/Incomplete/')\n",
    "directories.append(f'{local_folder}/Subjects/Groups/')\n",
    "directories.append(f'{local_folder}/Summary/')\n",
    "directories.append(f'{local_folder}/Ratings/')\n",
    "for movie in movie_names:\n",
    "    for rating in rating_types:\n",
    "        combo = movie + \"-\" + rating\n",
    "        movie_q_count_dict[combo] = 0\n",
    "        mov_to_sub[combo] = []\n",
    "        directories.append(f'{local_folder}/Ratings/{combo}/')\n",
    "        \n",
    "for directory in directories:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create blank pandas dataframes of proper shape to fill in with rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use provided movie durations to create blank dataframe of proper length for each movie\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "for movie in movie_names:\n",
    "    curr_vid_len = vid_lens[movie] + 3 # add buffer time\n",
    "    init_ratings = np.full(curr_vid_len, -1)\n",
    "    curr_df = pd.DataFrame({'rating': init_ratings})\n",
    "    curr_df.to_csv(os.path.join(blanks_path, f'{movie}.csv')) # write out to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read blank dataframes back in and store in dictionary\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "blank_pd_dict = {}\n",
    "directory_list = glob.glob(os.path.join(blanks_path, '*.csv'))\n",
    "for file in directory_list:\n",
    "    curr_df = pd.read_csv(file)\n",
    "    drop_df = curr_df.drop(labels='Unnamed: 0', axis=1)\n",
    "    movie = os.path.basename(file).split('.')[0]\n",
    "    blank_pd_dict[movie] = drop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which subjects completed task, and save subject info to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1731944933.960715 2225779 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n",
      "I0000 00:00:1731944933.977218 2225779 check_gcp_environment_no_op.cc:29] ALTS: Platforms other than Linux and Windows are not supported\n"
     ]
    }
   ],
   "source": [
    "# create good and bad subject lists (based on completion)\n",
    "good_id_master_list = []\n",
    "bad_id_master_list = []\n",
    "\n",
    "for group in groups:\n",
    "    good_id_list = [] # stores participants who completed HIT\n",
    "    bad_id_list = [] # stores participants who started but didn't complete HIT\n",
    "    sub_list = []\n",
    "\n",
    "    group_path = f'{experiment}/subjects/{group}'\n",
    "    group_collection = db.collection(group_path)\n",
    "    group_subs = group_collection.stream()\n",
    "\n",
    "    for sub in group_subs:\n",
    "        sub_dict = sub.to_dict()\n",
    "        if 'currentState' in sub_dict: # check to see if subject even started HIT\n",
    "            if sub_dict['currentState'] == 'debrief' or 'HIT_complete' in sub_dict: # only keep subs who finished\n",
    "                good_id_list.append(sub.id)\n",
    "                good_id_master_list.append(sub.id)\n",
    "                curr = pd.Series(sub_dict)\n",
    "                sub_list.append(curr)\n",
    "                file_path = f'{local_folder}/Subjects/{sub.id}.csv'\n",
    "                curr.to_csv(file_path)\n",
    "        else:\n",
    "            bad_id_list.append(sub.id)\n",
    "            bad_id_master_list.append(sub.id)\n",
    "            curr = pd.Series(sub_dict)\n",
    "            file_path = f'{local_folder}/Subjects/Incomplete/{sub.id}.csv'\n",
    "            curr.to_csv(file_path)\n",
    "\n",
    "    group_df = pd.DataFrame(sub_list)\n",
    "    group_df.to_csv(f'{local_folder}/Subjects/Groups/{group}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all ratings from subjects who completed task and store locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over subjects and gets ratings from database to store in local dictionary\n",
    "# also counts number of subjects that have rated each question\n",
    "# links subjects to movies and movies to subjects\n",
    "good_id_set = set(good_id_master_list) # removes repeats\n",
    "\n",
    "for good_id in good_id_set: \n",
    "    sub_to_mov[good_id] = []\n",
    "    movie_list = []\n",
    "    collection_path = f'{experiment}/ratings/{good_id}'\n",
    "    curr_sub_ratings = db.collection(collection_path)\n",
    "    HITs = curr_sub_ratings.stream()\n",
    "\n",
    "    curr_movie_dict = {}\n",
    "    for HIT in HITs:\n",
    "        sub_to_mov[good_id].append(HIT.id)\n",
    "        mov_to_sub[HIT.id].append(good_id)\n",
    "        curr_movie_dict[HIT.id] = HIT.to_dict()\n",
    "        movie_q_count_dict[HIT.id] += 1\n",
    "\n",
    "    if good_id in subject_rating_dict:\n",
    "        updated = subject_rating_dict[good_id].append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = updated\n",
    "    else:\n",
    "        movie_list.append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = movie_list\n",
    "\n",
    "movie_counts = pd.Series(movie_q_count_dict)\n",
    "movie_counts.to_csv(f'{local_folder}/Summary/Movie_Counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out rating dictionary to .csv rating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "9\n",
      "25\n",
      "41\n",
      "4\n",
      "3\n",
      "187\n",
      "431\n",
      "113\n",
      "123\n",
      "11\n",
      "9\n",
      "14\n",
      "18\n",
      "31\n",
      "17\n",
      "2\n",
      "1\n",
      "869\n",
      "868\n",
      "80\n",
      "87\n",
      "2\n",
      "75\n",
      "13\n",
      "5\n",
      "97\n",
      "85\n",
      "77\n",
      "60\n",
      "2\n",
      "173\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "190\n",
      "26\n",
      "2\n",
      "1\n",
      "63\n",
      "158\n",
      "206\n",
      "97\n",
      "253\n",
      "159\n",
      "135\n",
      "99\n",
      "143\n",
      "71\n",
      "2\n",
      "34\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "295\n",
      "357\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "147\n",
      "59\n",
      "16\n",
      "11\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "464\n",
      "575\n",
      "43\n",
      "32\n",
      "17\n",
      "11\n",
      "36\n",
      "24\n",
      "47\n",
      "5\n",
      "14\n",
      "4\n",
      "89\n",
      "21\n",
      "2\n",
      "74\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "61\n",
      "29\n",
      "15\n",
      "7\n",
      "52\n",
      "22\n",
      "2\n",
      "1\n",
      "127\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "# writes file containing rating-timestamp pairs for each subject to folder for each movie-rating pairing\n",
    "for good_id in good_id_set:\n",
    "    curr_sub = subject_rating_dict[good_id]\n",
    "    for dictionary in curr_sub:\n",
    "        for movie_rating in dictionary:\n",
    "            words = movie_rating.split('-')\n",
    "            blank_mov_pd = blank_pd_dict[words[0]].copy()\n",
    "            rating_dict = dictionary[movie_rating]\n",
    "            count = 0\n",
    "            print(len(rating_dict))\n",
    "            for timestamp in rating_dict:\n",
    "                    if timestamp.isdigit():\n",
    "                        blank_mov_pd.iloc[int(timestamp)] = rating_dict[timestamp]\n",
    "                    else:\n",
    "                        continue\n",
    "            file_path = f'{local_folder}/Ratings/{movie_rating}/{good_id}.csv'  \n",
    "            blank_mov_pd.to_csv(file_path)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine subject and rating info together to create long format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the base frame for appending\n",
    "cols = ['workerId', 'movie', 'ratingType', 'HIT_complete', 'age', 'assignmentId', 'birth', 'consentStatus', 'currentState', \\\n",
    "'ethnicity', 'feedback', 'handed', 'hitId', 'nativeLang', 'race', 'sex', 'startTime', \\\n",
    "'userId', 'mostRecentTime', 'timeStamp', 'ratingScore']\n",
    "\n",
    "base_frame = pd.DataFrame(np.nan, index=[0], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this take individual local csvs and turns them into long format per movie per rating per subject\n",
    "dir_list = glob.glob(f'{local_folder}/Ratings/*')\n",
    "master_long = base_frame.copy()\n",
    "\n",
    "for directory in dir_list:\n",
    "    path = directory + '/*.csv'\n",
    "    rating_list = glob.glob(path)\n",
    "    for file in rating_list:\n",
    "        sub_id = os.path.basename(file).split('.')[0]\n",
    "        movie_rating = file.split('/')[2]\n",
    "        movie = movie_rating.split('-')[0]\n",
    "        rating = movie_rating.split('-')[0]       \n",
    "\n",
    "        # this should check and not rewrite files that already exist (speeds up process)\n",
    "        if not os.path.isfile(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv'):\n",
    "            subject_long = base_frame.copy()\n",
    "            rating_pd = pd.read_csv(file)\n",
    "            sub_path = f'{local_folder}/Subjects/{sub_id}.csv'\n",
    "            if os.path.isfile(sub_path):\n",
    "                sub_pd = pd.read_csv(sub_path)\n",
    "                title_list = sub_pd['Unnamed: 0'].values\n",
    "                rename_dict = {}\n",
    "                counter = 0\n",
    "                for title in title_list:\n",
    "                    rename_dict[counter] = title\n",
    "                    counter += 1   \n",
    "                new_sub_pd = sub_pd.transpose().rename(columns=rename_dict).drop(['Unnamed: 0'])\n",
    "\n",
    "                new_pd = base_frame.copy()\n",
    "                new_pd['movie'] = movie\n",
    "                new_pd['ratingType'] = rating\n",
    "\n",
    "                for category in base_frame:\n",
    "                    if category in new_sub_pd:\n",
    "                        new_pd[category] = new_sub_pd[category].values\n",
    "\n",
    "                timestamp_dict = rating_pd.transpose().drop(['Unnamed: 0'])\n",
    "                copy_pd = new_pd.copy()\n",
    "                prevScore = -1\n",
    "                rating_counter = 0\n",
    "                for timestamp in timestamp_dict:\n",
    "                    ratingScore = timestamp_dict[timestamp].values\n",
    "                    if ratingScore != -1:\n",
    "                        prevScore = ratingScore\n",
    "                    else:\n",
    "                        ratingScore = prevScore\n",
    "\n",
    "                    copy_pd['timeStamp'] = timestamp\n",
    "                    copy_pd['ratingScore'] = ratingScore\n",
    "                    subject_long = pd.concat([subject_long, copy_pd], ignore_index=True)\n",
    "\n",
    "                subject_long = subject_long.drop([0])\n",
    "                subject_long.to_csv(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this appends all individual long format files into one giant long format panda\n",
    "master_long = base_frame.copy()\n",
    "long_list = glob.glob(f'{local_folder}/Long/*.csv')\n",
    "\n",
    "for file in long_list:\n",
    "    curr_pd = pd.read_csv(file)\n",
    "    master_long = pd.concat([master_long, curr_pd])\n",
    "\n",
    "master_long.drop([0])\n",
    "master_long.to_csv(f'{local_folder}/master_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in saved copy\n",
    "master_long = pd.read_csv(f'{local_folder}/master_long.csv')\n",
    "master_long.drop(labels=[0], inplace=True)\n",
    "master_long.drop(labels=['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "sub_list = master_long['workerId'].unique()\n",
    "movie_list = master_long['movie'].unique()\n",
    "rating_list = master_long['ratingType'].unique()\n",
    "movie = movie_list[0]\n",
    "rating = rating_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerId</th>\n",
       "      <th>movie</th>\n",
       "      <th>ratingType</th>\n",
       "      <th>HIT_complete</th>\n",
       "      <th>age</th>\n",
       "      <th>assignmentId</th>\n",
       "      <th>birth</th>\n",
       "      <th>consentStatus</th>\n",
       "      <th>currentState</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>handed</th>\n",
       "      <th>hitId</th>\n",
       "      <th>nativeLang</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>startTime</th>\n",
       "      <th>userId</th>\n",
       "      <th>mostRecentTime</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>ratingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>695941583.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>Benoni, Gauteng, South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>ZZ7iUiFkwie4FNH4wxzm9BxCVbO2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>695941583.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>Benoni, Gauteng, South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>ZZ7iUiFkwie4FNH4wxzm9BxCVbO2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>695941583.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>Benoni, Gauteng, South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>ZZ7iUiFkwie4FNH4wxzm9BxCVbO2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>695941583.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>Benoni, Gauteng, South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>ZZ7iUiFkwie4FNH4wxzm9BxCVbO2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>695941583.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>Benoni, Gauteng, South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>695941583.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-17 18:43:39.536000+00:00</td>\n",
       "      <td>ZZ7iUiFkwie4FNH4wxzm9BxCVbO2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59772</th>\n",
       "      <td>200521428.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>2Jvkta1VsEes9fbrOg9l6AdhcRt1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59773</th>\n",
       "      <td>200521428.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>2Jvkta1VsEes9fbrOg9l6AdhcRt1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>930.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59774</th>\n",
       "      <td>200521428.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>2Jvkta1VsEes9fbrOg9l6AdhcRt1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>931.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59775</th>\n",
       "      <td>200521428.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>2Jvkta1VsEes9fbrOg9l6AdhcRt1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>932.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59776</th>\n",
       "      <td>200521428.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>200521428.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2024-11-16 12:33:13.796000+00:00</td>\n",
       "      <td>2Jvkta1VsEes9fbrOg9l6AdhcRt1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>933.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59776 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          workerId       movie  ratingType                      HIT_complete  \\\n",
       "1      695941583.0  jasondavis  jasondavis  2024-11-17 18:43:39.536000+00:00   \n",
       "2      695941583.0  jasondavis  jasondavis  2024-11-17 18:43:39.536000+00:00   \n",
       "3      695941583.0  jasondavis  jasondavis  2024-11-17 18:43:39.536000+00:00   \n",
       "4      695941583.0  jasondavis  jasondavis  2024-11-17 18:43:39.536000+00:00   \n",
       "5      695941583.0  jasondavis  jasondavis  2024-11-17 18:43:39.536000+00:00   \n",
       "...            ...         ...         ...                               ...   \n",
       "59772  200521428.0  jasondavis  jasondavis  2024-11-16 12:33:13.796000+00:00   \n",
       "59773  200521428.0  jasondavis  jasondavis  2024-11-16 12:33:13.796000+00:00   \n",
       "59774  200521428.0  jasondavis  jasondavis  2024-11-16 12:33:13.796000+00:00   \n",
       "59775  200521428.0  jasondavis  jasondavis  2024-11-16 12:33:13.796000+00:00   \n",
       "59776  200521428.0  jasondavis  jasondavis  2024-11-16 12:33:13.796000+00:00   \n",
       "\n",
       "        age  assignmentId                          birth consentStatus  \\\n",
       "1      34.0   695941583.0  Benoni, Gauteng, South Africa        signed   \n",
       "2      34.0   695941583.0  Benoni, Gauteng, South Africa        signed   \n",
       "3      34.0   695941583.0  Benoni, Gauteng, South Africa        signed   \n",
       "4      34.0   695941583.0  Benoni, Gauteng, South Africa        signed   \n",
       "5      34.0   695941583.0  Benoni, Gauteng, South Africa        signed   \n",
       "...     ...           ...                            ...           ...   \n",
       "59772  52.0   200521428.0                   South Africa        signed   \n",
       "59773  52.0   200521428.0                   South Africa        signed   \n",
       "59774  52.0   200521428.0                   South Africa        signed   \n",
       "59775  52.0   200521428.0                   South Africa        signed   \n",
       "59776  52.0   200521428.0                   South Africa        signed   \n",
       "\n",
       "      currentState     ethnicity  ... handed        hitId  nativeLang  \\\n",
       "1         complete  not_hispanic  ...  right  695941583.0     English   \n",
       "2         complete  not_hispanic  ...  right  695941583.0     English   \n",
       "3         complete  not_hispanic  ...  right  695941583.0     English   \n",
       "4         complete  not_hispanic  ...  right  695941583.0     English   \n",
       "5         complete  not_hispanic  ...  right  695941583.0     English   \n",
       "...            ...           ...  ...    ...          ...         ...   \n",
       "59772     complete  not_hispanic  ...  right  200521428.0     English   \n",
       "59773     complete  not_hispanic  ...  right  200521428.0     English   \n",
       "59774     complete  not_hispanic  ...  right  200521428.0     English   \n",
       "59775     complete  not_hispanic  ...  right  200521428.0     English   \n",
       "59776     complete  not_hispanic  ...  right  200521428.0     English   \n",
       "\n",
       "                               race     sex                         startTime  \\\n",
       "1      ['Black / African-American']  female  2024-11-17 18:43:39.536000+00:00   \n",
       "2      ['Black / African-American']  female  2024-11-17 18:43:39.536000+00:00   \n",
       "3      ['Black / African-American']  female  2024-11-17 18:43:39.536000+00:00   \n",
       "4      ['Black / African-American']  female  2024-11-17 18:43:39.536000+00:00   \n",
       "5      ['Black / African-American']  female  2024-11-17 18:43:39.536000+00:00   \n",
       "...                             ...     ...                               ...   \n",
       "59772  ['Black / African-American']  female  2024-11-16 12:33:13.796000+00:00   \n",
       "59773  ['Black / African-American']  female  2024-11-16 12:33:13.796000+00:00   \n",
       "59774  ['Black / African-American']  female  2024-11-16 12:33:13.796000+00:00   \n",
       "59775  ['Black / African-American']  female  2024-11-16 12:33:13.796000+00:00   \n",
       "59776  ['Black / African-American']  female  2024-11-16 12:33:13.796000+00:00   \n",
       "\n",
       "                             userId mostRecentTime  timeStamp  ratingScore  \n",
       "1      ZZ7iUiFkwie4FNH4wxzm9BxCVbO2            NaN        0.0         50.0  \n",
       "2      ZZ7iUiFkwie4FNH4wxzm9BxCVbO2            NaN        1.0         50.0  \n",
       "3      ZZ7iUiFkwie4FNH4wxzm9BxCVbO2            NaN        2.0         50.0  \n",
       "4      ZZ7iUiFkwie4FNH4wxzm9BxCVbO2            NaN        3.0         50.0  \n",
       "5      ZZ7iUiFkwie4FNH4wxzm9BxCVbO2            NaN        4.0         50.0  \n",
       "...                             ...            ...        ...          ...  \n",
       "59772  2Jvkta1VsEes9fbrOg9l6AdhcRt1            NaN      929.0         58.0  \n",
       "59773  2Jvkta1VsEes9fbrOg9l6AdhcRt1            NaN      930.0         58.0  \n",
       "59774  2Jvkta1VsEes9fbrOg9l6AdhcRt1            NaN      931.0         58.0  \n",
       "59775  2Jvkta1VsEes9fbrOg9l6AdhcRt1            NaN      932.0         58.0  \n",
       "59776  2Jvkta1VsEes9fbrOg9l6AdhcRt1            NaN      933.0         58.0  \n",
       "\n",
       "[59776 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
