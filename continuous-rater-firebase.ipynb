{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasondavis/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "from firebase_admin import auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add user input\n",
    "Fill in the variables in the cell below with the following information\n",
    "\n",
    "- `experiment` = name of experiment (outermost collection) in Firebase\n",
    "- `local_folder` = name of folder you want created locally and populated with data\n",
    "- `credential_path` = path to .json Firebase SDK service account key (explained [here](https://firebase.google.com/docs/admin/setup))\n",
    "- `firebase_project_name` = name of project in Firebase (click Project Overview in the Firebase console to see name)\n",
    "- `groups` = array of group names (as set by userGroup in src/utils.js and found as collections in the 'subject' document in your Firebase), each enclosed in single quotes and separated by commas\n",
    "- `rating_types` = array of rating types, each enclosed in single quotes and separated by commas (same as ratingTypes from src/utils.js)\n",
    "- `movie_names` = array of movie names, as written in Firebase stimuli table (no spaces), each enclosed in single quotes and separated by commas\n",
    "- `vid_lens` = dictionary of video durations, where each entry contains the movie name as key and the movie duration (in seconds) as value (e.g. {'movie1': 100, 'movie2': 150, 'movie3': 120}) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER VARIABLES (FILL IN HERE)\n",
    "experiment = 'wasabi-online'\n",
    "local_folder = '/Users/jasondavis/Documents/MATLAB/state_affect_mapping_jad/wasabi_online/'\n",
    "credential_path = '/Users/jasondavis/Documents/Downloads/continuous-rater-jad-firebase-adminsdk-2ie9g-0080d92b8a.json'\n",
    "firebase_project_name = 'continuous-rater-jad'\n",
    "groups = ['Kung Fury Study 3'] # possible to only have on group, or can use multiple for organizational purposes\n",
    "rating_types = ['pleasant', 'unpleasant', 'calm', 'aroused', 'funny', 'happy', 'angry', 'sad', 'disgusted', 'afraid', 'surprised', 'neutral']\n",
    "movie_names = ['ColdWar', 'KungFuryPart1', 'KungFuryPart2']\n",
    "vid_lens = {'ColdWar':999,'KungFuryPart1': 931, 'KungFuryPart2': 931} # example values, fill in with your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up communication with Firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cred \u001b[38;5;241m=\u001b[39m credentials\u001b[38;5;241m.\u001b[39mCertificate(credential_path)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfirebase_admin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_app\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprojectId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirebase_project_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m db \u001b[38;5;241m=\u001b[39m firestore\u001b[38;5;241m.\u001b[39mclient()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/firebase_admin/__init__.py:74\u001b[0m, in \u001b[0;36minitialize_app\u001b[0;34m(credential, options, name)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m app\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m _DEFAULT_APP_NAME:\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe default Firebase app already exists. This means you called \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize_app() more than once without providing an app name as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe second argument. In most cases you only need to call \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize_app() once. But if you do want to initialize multiple \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapps, pass a second argument to initialize_app() to give each app \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma unique name.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m((\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirebase app named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m already exists. This means you called \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitialize_app() more than once with the same app name as the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecond argument. Make sure you provide a unique name every time \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myou call initialize_app().\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(name))\n",
      "\u001b[0;31mValueError\u001b[0m: The default Firebase app already exists. This means you called initialize_app() more than once without providing an app name as the second argument. In most cases you only need to call initialize_app() once. But if you do want to initialize multiple apps, pass a second argument to initialize_app() to give each app a unique name."
     ]
    }
   ],
   "source": [
    "cred = credentials.Certificate(credential_path)\n",
    "firebase_admin.initialize_app(cred, {\n",
    "  'projectId': firebase_project_name,\n",
    "})\n",
    "\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize data structures and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data structures\n",
    "subject_rating_dict = {}\n",
    "movie_q_count_dict = {}\n",
    "sub_to_mov = {}\n",
    "mov_to_sub = {}\n",
    "\n",
    "# initialize directory structure\n",
    "directories = []\n",
    "directories.append(f'{local_folder}/')\n",
    "directories.append(f'{local_folder}/Long/')\n",
    "directories.append(f'{local_folder}/Blanks/')\n",
    "directories.append(f'{local_folder}/Subjects/')\n",
    "directories.append(f'{local_folder}/Subjects/Incomplete/')\n",
    "directories.append(f'{local_folder}/Subjects/Groups/')\n",
    "directories.append(f'{local_folder}/Summary/')\n",
    "directories.append(f'{local_folder}/Ratings/')\n",
    "for movie in movie_names:\n",
    "    for rating in rating_types:\n",
    "        combo = movie + \"-\" + rating\n",
    "        movie_q_count_dict[combo] = 0\n",
    "        mov_to_sub[combo] = []\n",
    "        directories.append(f'{local_folder}/Ratings/{combo}/')\n",
    "        \n",
    "for directory in directories:\n",
    "    if not os.path.isdir(directory):\n",
    "        os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create blank pandas dataframes of proper shape to fill in with rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use provided movie durations to create blank dataframe of proper length for each movie\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "for movie in movie_names:\n",
    "    curr_vid_len = vid_lens[movie] + 3 # add buffer time\n",
    "    init_ratings = np.full(curr_vid_len, -1)\n",
    "    curr_df = pd.DataFrame({'rating': init_ratings})\n",
    "    curr_df.to_csv(os.path.join(blanks_path, f'{movie}.csv')) # write out to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read blank dataframes back in and store in dictionary\n",
    "blanks_path = f'{local_folder}/Blanks/'\n",
    "blank_pd_dict = {}\n",
    "directory_list = glob.glob(os.path.join(blanks_path, '*.csv'))\n",
    "for file in directory_list:\n",
    "    curr_df = pd.read_csv(file)\n",
    "    drop_df = curr_df.drop(labels='Unnamed: 0', axis=1)\n",
    "    movie = os.path.basename(file).split('.')[0]\n",
    "    blank_pd_dict[movie] = drop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which subjects completed task, and save subject info to .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create good and bad subject lists (based on completion)\n",
    "good_id_master_list = []\n",
    "bad_id_master_list = []\n",
    "\n",
    "for group in groups:\n",
    "    good_id_list = [] # stores participants who completed HIT\n",
    "    bad_id_list = [] # stores participants who started but didn't complete HIT\n",
    "    sub_list = []\n",
    "\n",
    "    group_path = f'{experiment}/subjects/{group}'\n",
    "    group_collection = db.collection(group_path)\n",
    "    group_subs = group_collection.stream()\n",
    "\n",
    "    for sub in group_subs:\n",
    "        sub_dict = sub.to_dict()\n",
    "        if 'currentState' in sub_dict: # check to see if subject even started HIT\n",
    "            if sub_dict['currentState'] == 'debrief' or 'HIT_complete' in sub_dict: # only keep subs who finished\n",
    "                good_id_list.append(sub.id)\n",
    "                good_id_master_list.append(sub.id)\n",
    "                curr = pd.Series(sub_dict)\n",
    "                sub_list.append(curr)\n",
    "                file_path = f'{local_folder}/Subjects/{sub.id}.csv'\n",
    "                curr.to_csv(file_path)\n",
    "        else:\n",
    "            bad_id_list.append(sub.id)\n",
    "            bad_id_master_list.append(sub.id)\n",
    "            curr = pd.Series(sub_dict)\n",
    "            file_path = f'{local_folder}/Subjects/Incomplete/{sub.id}.csv'\n",
    "            curr.to_csv(file_path)\n",
    "\n",
    "    group_df = pd.DataFrame(sub_list)\n",
    "    group_df.to_csv(f'{local_folder}/Subjects/Groups/{group}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all ratings from subjects who completed task and store locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over subjects and gets ratings from database to store in local dictionary\n",
    "# also counts number of subjects that have rated each question\n",
    "# links subjects to movies and movies to subjects\n",
    "good_id_set = set(good_id_master_list) # removes repeats\n",
    "\n",
    "for good_id in good_id_set: \n",
    "    sub_to_mov[good_id] = []\n",
    "    movie_list = []\n",
    "    collection_path = f'{experiment}/ratings/{good_id}'\n",
    "    curr_sub_ratings = db.collection(collection_path)\n",
    "    HITs = curr_sub_ratings.stream()\n",
    "\n",
    "    curr_movie_dict = {}\n",
    "    for HIT in HITs:\n",
    "        sub_to_mov[good_id].append(HIT.id)\n",
    "        mov_to_sub[HIT.id].append(good_id)\n",
    "        curr_movie_dict[HIT.id] = HIT.to_dict()\n",
    "        movie_q_count_dict[HIT.id] += 1\n",
    "\n",
    "    if good_id in subject_rating_dict:\n",
    "        updated = subject_rating_dict[good_id].append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = updated\n",
    "    else:\n",
    "        movie_list.append(curr_movie_dict)\n",
    "        subject_rating_dict[good_id] = movie_list\n",
    "\n",
    "movie_counts = pd.Series(movie_q_count_dict)\n",
    "movie_counts.to_csv(f'{local_folder}/Summary/Movie_Counts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out rating dictionary to .csv rating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "267\n",
      "347\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "69\n",
      "64\n",
      "39\n",
      "115\n",
      "95\n",
      "36\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "46\n",
      "17\n",
      "17\n",
      "16\n",
      "7\n",
      "34\n",
      "16\n",
      "8\n",
      "2\n",
      "9\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "331\n",
      "134\n",
      "81\n",
      "45\n",
      "17\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "9\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "6\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "13\n",
      "32\n",
      "20\n",
      "23\n",
      "17\n",
      "37\n",
      "32\n",
      "56\n",
      "37\n",
      "52\n",
      "4\n",
      "9\n",
      "25\n",
      "67\n",
      "78\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "29\n",
      "159\n",
      "201\n",
      "19\n",
      "4\n",
      "1\n",
      "21\n",
      "7\n",
      "11\n",
      "68\n",
      "2\n",
      "18\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "8\n",
      "8\n",
      "2\n",
      "2\n",
      "1\n",
      "239\n",
      "88\n",
      "58\n",
      "2\n",
      "2\n",
      "1\n",
      "228\n",
      "221\n",
      "284\n",
      "8\n",
      "9\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "59\n",
      "65\n",
      "6\n",
      "5\n",
      "5\n",
      "1\n",
      "54\n",
      "35\n",
      "15\n",
      "14\n",
      "7\n",
      "8\n",
      "8\n",
      "166\n",
      "47\n",
      "3\n",
      "16\n",
      "6\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "120\n",
      "43\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "14\n",
      "16\n",
      "2\n",
      "13\n",
      "1\n",
      "2\n",
      "2\n",
      "8\n",
      "63\n",
      "56\n",
      "90\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "9\n",
      "13\n",
      "219\n",
      "157\n",
      "142\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "8\n",
      "7\n",
      "8\n",
      "2\n",
      "2\n",
      "1\n",
      "36\n",
      "21\n",
      "27\n",
      "2\n",
      "2\n",
      "1\n",
      "186\n",
      "157\n",
      "106\n",
      "6\n",
      "7\n",
      "7\n",
      "44\n",
      "23\n",
      "26\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "9\n",
      "193\n",
      "143\n",
      "117\n",
      "245\n",
      "67\n",
      "48\n",
      "2\n",
      "2\n",
      "1\n",
      "19\n",
      "12\n",
      "5\n",
      "16\n",
      "27\n",
      "52\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "14\n",
      "3\n",
      "43\n",
      "57\n",
      "56\n",
      "2\n",
      "2\n",
      "1\n",
      "9\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "1\n",
      "5\n",
      "8\n",
      "13\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "157\n",
      "120\n",
      "128\n",
      "45\n",
      "108\n",
      "97\n",
      "21\n",
      "111\n",
      "77\n",
      "44\n",
      "34\n",
      "27\n",
      "102\n",
      "147\n",
      "97\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "26\n",
      "4\n",
      "25\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "307\n",
      "241\n",
      "272\n",
      "7\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "56\n",
      "4\n",
      "25\n",
      "2\n",
      "193\n",
      "174\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "131\n",
      "28\n",
      "21\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "22\n",
      "2\n",
      "2\n",
      "7\n",
      "2\n",
      "2\n",
      "9\n",
      "8\n",
      "7\n",
      "1\n",
      "191\n",
      "208\n",
      "111\n",
      "332\n",
      "226\n",
      "251\n",
      "3\n",
      "3\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "3\n",
      "2\n",
      "80\n",
      "72\n",
      "67\n",
      "2\n",
      "2\n",
      "1\n",
      "14\n",
      "2\n",
      "7\n",
      "2\n",
      "15\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "229\n",
      "149\n",
      "121\n",
      "7\n",
      "12\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "53\n",
      "89\n",
      "82\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "26\n",
      "23\n",
      "15\n",
      "13\n",
      "2\n",
      "13\n",
      "13\n",
      "38\n",
      "39\n",
      "26\n",
      "3\n",
      "3\n",
      "2\n",
      "12\n",
      "68\n",
      "71\n",
      "10\n",
      "2\n",
      "2\n",
      "13\n",
      "52\n",
      "14\n",
      "30\n",
      "389\n",
      "340\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "1\n",
      "58\n",
      "64\n",
      "19\n",
      "19\n",
      "4\n",
      "1\n",
      "8\n",
      "4\n",
      "4\n",
      "29\n",
      "29\n",
      "30\n",
      "2\n",
      "2\n",
      "1\n",
      "65\n",
      "24\n",
      "11\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "18\n",
      "16\n",
      "6\n",
      "7\n",
      "4\n",
      "5\n",
      "4\n",
      "41\n",
      "69\n",
      "85\n",
      "2\n",
      "2\n",
      "1\n",
      "17\n",
      "7\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "218\n",
      "27\n",
      "38\n",
      "2\n",
      "2\n",
      "1\n",
      "239\n",
      "129\n",
      "88\n",
      "6\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "44\n",
      "9\n",
      "34\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "135\n",
      "59\n",
      "56\n",
      "2\n",
      "2\n",
      "1\n",
      "36\n",
      "33\n",
      "22\n",
      "7\n",
      "5\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "49\n",
      "65\n",
      "69\n",
      "2\n",
      "2\n",
      "6\n",
      "53\n",
      "21\n",
      "16\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "130\n",
      "57\n",
      "58\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "8\n",
      "4\n",
      "20\n",
      "15\n",
      "9\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "10\n",
      "13\n",
      "2\n",
      "2\n",
      "1\n",
      "11\n",
      "31\n",
      "31\n",
      "8\n",
      "6\n",
      "6\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "3\n",
      "3\n",
      "2\n",
      "11\n",
      "2\n",
      "6\n",
      "79\n",
      "145\n",
      "108\n",
      "28\n",
      "16\n",
      "3\n",
      "4\n",
      "31\n",
      "17\n",
      "2\n",
      "2\n",
      "1\n",
      "116\n",
      "162\n",
      "80\n",
      "2\n",
      "13\n",
      "14\n",
      "530\n",
      "532\n",
      "403\n",
      "2\n",
      "2\n",
      "13\n",
      "8\n",
      "17\n",
      "10\n",
      "10\n",
      "6\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "38\n",
      "31\n",
      "21\n",
      "108\n",
      "58\n",
      "36\n",
      "54\n",
      "31\n",
      "13\n",
      "24\n",
      "16\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "57\n",
      "76\n",
      "37\n",
      "2\n",
      "2\n",
      "1\n",
      "58\n",
      "78\n",
      "16\n",
      "329\n",
      "130\n",
      "132\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "99\n",
      "41\n",
      "129\n",
      "169\n",
      "149\n",
      "4\n",
      "9\n",
      "18\n",
      "58\n",
      "86\n",
      "85\n",
      "15\n",
      "9\n",
      "11\n",
      "2\n",
      "2\n",
      "1\n",
      "11\n",
      "8\n",
      "32\n",
      "2\n",
      "2\n",
      "4\n",
      "147\n",
      "42\n",
      "50\n",
      "56\n",
      "52\n",
      "81\n",
      "314\n",
      "277\n",
      "219\n",
      "2\n",
      "2\n",
      "1\n",
      "187\n",
      "26\n",
      "50\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "9\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "6\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# writes file containing rating-timestamp pairs for each subject to folder for each movie-rating pairing\n",
    "for good_id in good_id_set:\n",
    "    curr_sub = subject_rating_dict[good_id]\n",
    "    for dictionary in curr_sub:\n",
    "        for movie_rating in dictionary:\n",
    "            words = movie_rating.split('-')\n",
    "            blank_mov_pd = blank_pd_dict[words[0]].copy()\n",
    "            rating_dict = dictionary[movie_rating]\n",
    "            count = 0\n",
    "            print(len(rating_dict))\n",
    "            for timestamp in rating_dict:\n",
    "                    if timestamp.isdigit():\n",
    "                        blank_mov_pd.iloc[int(timestamp)] = rating_dict[timestamp]\n",
    "                    else:\n",
    "                        continue\n",
    "            file_path = f'{local_folder}/Ratings/{movie_rating}/{good_id}.csv'  \n",
    "            blank_mov_pd.to_csv(file_path)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine subject and rating info together to create long format file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the base frame for appending\n",
    "cols = ['workerId', 'movie', 'ratingType', 'HIT_complete', 'age', 'assignmentId', 'birth', 'consentStatus', 'currentState', \\\n",
    "'ethnicity', 'feedback', 'handed', 'hitId', 'nativeLang', 'race', 'sex', 'startTime', \\\n",
    "'userId', 'mostRecentTime', 'timeStamp', 'ratingScore']\n",
    "\n",
    "base_frame = pd.DataFrame(np.nan, index=[0], columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this take individual local csvs and turns them into long format per movie per rating per subject\n",
    "dir_list = glob.glob(f'{local_folder}/Ratings/*')\n",
    "master_long = base_frame.copy()\n",
    "\n",
    "for directory in dir_list:\n",
    "    path = directory + '/*.csv'\n",
    "    rating_list = glob.glob(path)\n",
    "    for file in rating_list:\n",
    "        sub_id = os.path.basename(file).split('.')[0]\n",
    "        movie_rating = file.split('/')[2]\n",
    "        movie = movie_rating.split('-')[0]\n",
    "        rating = movie_rating.split('-')[0]       \n",
    "\n",
    "        # this should check and not rewrite files that already exist (speeds up process)\n",
    "        if not os.path.isfile(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv'):\n",
    "            subject_long = base_frame.copy()\n",
    "            rating_pd = pd.read_csv(file)\n",
    "            sub_path = f'{local_folder}/Subjects/{sub_id}.csv'\n",
    "            if os.path.isfile(sub_path):\n",
    "                sub_pd = pd.read_csv(sub_path)\n",
    "                title_list = sub_pd['Unnamed: 0'].values\n",
    "                rename_dict = {}\n",
    "                counter = 0\n",
    "                for title in title_list:\n",
    "                    rename_dict[counter] = title\n",
    "                    counter += 1   \n",
    "                new_sub_pd = sub_pd.transpose().rename(columns=rename_dict).drop(['Unnamed: 0'])\n",
    "\n",
    "                new_pd = base_frame.copy()\n",
    "                new_pd['movie'] = movie\n",
    "                new_pd['ratingType'] = rating\n",
    "\n",
    "                for category in base_frame:\n",
    "                    if category in new_sub_pd:\n",
    "                        new_pd[category] = new_sub_pd[category].values\n",
    "\n",
    "                timestamp_dict = rating_pd.transpose().drop(['Unnamed: 0'])\n",
    "                copy_pd = new_pd.copy()\n",
    "                prevScore = -1\n",
    "                rating_counter = 0\n",
    "                for timestamp in timestamp_dict:\n",
    "                    ratingScore = timestamp_dict[timestamp].values\n",
    "                    if ratingScore != -1:\n",
    "                        prevScore = ratingScore\n",
    "                    else:\n",
    "                        ratingScore = prevScore\n",
    "\n",
    "                    copy_pd['timeStamp'] = timestamp\n",
    "                    copy_pd['ratingScore'] = ratingScore\n",
    "                    subject_long = pd.concat([subject_long, copy_pd], ignore_index=True)\n",
    "\n",
    "                subject_long = subject_long.drop([0])\n",
    "                subject_long.to_csv(f'{local_folder}/Long/{movie}-{rating}-{sub_id}.csv')                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this appends all individual long format files into one giant long format panda\n",
    "master_long = base_frame.copy()\n",
    "long_list = glob.glob(f'{local_folder}/Long/*.csv')\n",
    "\n",
    "for file in long_list:\n",
    "    curr_pd = pd.read_csv(file)\n",
    "    master_long = pd.concat([master_long, curr_pd])\n",
    "\n",
    "master_long.drop([0])\n",
    "master_long.to_csv(f'{local_folder}/master_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in saved copy\n",
    "master_long = pd.read_csv(f'{local_folder}/master_long.csv')\n",
    "master_long.drop(labels=[0], inplace=True)\n",
    "master_long.drop(labels=['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "sub_list = master_long['workerId'].unique()\n",
    "movie_list = master_long['movie'].unique()\n",
    "rating_list = master_long['ratingType'].unique()\n",
    "movie = movie_list[0]\n",
    "rating = rating_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workerId</th>\n",
       "      <th>movie</th>\n",
       "      <th>ratingType</th>\n",
       "      <th>HIT_complete</th>\n",
       "      <th>age</th>\n",
       "      <th>assignmentId</th>\n",
       "      <th>birth</th>\n",
       "      <th>consentStatus</th>\n",
       "      <th>currentState</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>handed</th>\n",
       "      <th>hitId</th>\n",
       "      <th>nativeLang</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>startTime</th>\n",
       "      <th>userId</th>\n",
       "      <th>mostRecentTime</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>ratingScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>521709877.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>SOUTH AFRICA</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>not_hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>521709877.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>female</td>\n",
       "      <td>2025-06-11 12:22:50.326000+00:00</td>\n",
       "      <td>KqVBrnp1VPfrgMQEjxps6d8X5wM2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240886</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>929.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240887</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>930.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240888</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>931.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240889</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>932.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240890</th>\n",
       "      <td>405819037.0</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>jasondavis</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>signed</td>\n",
       "      <td>complete</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>...</td>\n",
       "      <td>right</td>\n",
       "      <td>405819037.0</td>\n",
       "      <td>English</td>\n",
       "      <td>['Black / African-American']</td>\n",
       "      <td>male</td>\n",
       "      <td>2025-05-30 09:20:21.378000+00:00</td>\n",
       "      <td>Cuys5RYuuNbdvEc5ITkUWhFSfEJ3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>933.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240890 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           workerId       movie  ratingType                      HIT_complete  \\\n",
       "1       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "2       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "3       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "4       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "5       521709877.0  jasondavis  jasondavis  2025-06-11 12:22:50.326000+00:00   \n",
       "...             ...         ...         ...                               ...   \n",
       "240886  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240887  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240888  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240889  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "240890  405819037.0  jasondavis  jasondavis  2025-05-30 09:20:21.378000+00:00   \n",
       "\n",
       "         age  assignmentId          birth consentStatus currentState  \\\n",
       "1       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "2       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "3       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "4       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "5       54.0   521709877.0   SOUTH AFRICA        signed     complete   \n",
       "...      ...           ...            ...           ...          ...   \n",
       "240886  31.0   405819037.0  South Africa         signed     complete   \n",
       "240887  31.0   405819037.0  South Africa         signed     complete   \n",
       "240888  31.0   405819037.0  South Africa         signed     complete   \n",
       "240889  31.0   405819037.0  South Africa         signed     complete   \n",
       "240890  31.0   405819037.0  South Africa         signed     complete   \n",
       "\n",
       "           ethnicity  ... handed        hitId  nativeLang  \\\n",
       "1       not_hispanic  ...  right  521709877.0     English   \n",
       "2       not_hispanic  ...  right  521709877.0     English   \n",
       "3       not_hispanic  ...  right  521709877.0     English   \n",
       "4       not_hispanic  ...  right  521709877.0     English   \n",
       "5       not_hispanic  ...  right  521709877.0     English   \n",
       "...              ...  ...    ...          ...         ...   \n",
       "240886      hispanic  ...  right  405819037.0    English    \n",
       "240887      hispanic  ...  right  405819037.0    English    \n",
       "240888      hispanic  ...  right  405819037.0    English    \n",
       "240889      hispanic  ...  right  405819037.0    English    \n",
       "240890      hispanic  ...  right  405819037.0    English    \n",
       "\n",
       "                                race     sex  \\\n",
       "1       ['Black / African-American']  female   \n",
       "2       ['Black / African-American']  female   \n",
       "3       ['Black / African-American']  female   \n",
       "4       ['Black / African-American']  female   \n",
       "5       ['Black / African-American']  female   \n",
       "...                              ...     ...   \n",
       "240886  ['Black / African-American']    male   \n",
       "240887  ['Black / African-American']    male   \n",
       "240888  ['Black / African-American']    male   \n",
       "240889  ['Black / African-American']    male   \n",
       "240890  ['Black / African-American']    male   \n",
       "\n",
       "                               startTime                        userId  \\\n",
       "1       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "2       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "3       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "4       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "5       2025-06-11 12:22:50.326000+00:00  KqVBrnp1VPfrgMQEjxps6d8X5wM2   \n",
       "...                                  ...                           ...   \n",
       "240886  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240887  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240888  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240889  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "240890  2025-05-30 09:20:21.378000+00:00  Cuys5RYuuNbdvEc5ITkUWhFSfEJ3   \n",
       "\n",
       "       mostRecentTime  timeStamp  ratingScore  \n",
       "1                 NaN        0.0         50.0  \n",
       "2                 NaN        1.0         50.0  \n",
       "3                 NaN        2.0         50.0  \n",
       "4                 NaN        3.0         50.0  \n",
       "5                 NaN        4.0         50.0  \n",
       "...               ...        ...          ...  \n",
       "240886            NaN      929.0         50.0  \n",
       "240887            NaN      930.0         50.0  \n",
       "240888            NaN      931.0         50.0  \n",
       "240889            NaN      932.0         50.0  \n",
       "240890            NaN      933.0         50.0  \n",
       "\n",
       "[240890 rows x 21 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_long"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
